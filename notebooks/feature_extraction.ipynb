{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook there the:\n",
    "- extraction of the audios and the labels from the paths \n",
    "- filtering of the audios\n",
    "- extraction of features in time-domain, frequency-domain, MFCCs, Chroma, fundamental frequency and amplitude envelope\n",
    "- result a combined dataframe (raw df + feature extracted)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_audio_files\n",
    "from utils import extract_labels\n",
    "\n",
    "train_path = '/Users/fabiodepetro/DSL_Project/ProvaProgetto/DSL_Winter_Project_2025/audios_development'\n",
    "eval_path = '/Users/fabiodepetro/DSL_Project/ProvaProgetto/DSL_Winter_Project_2025/audios_evaluation'\n",
    "\n",
    "signals_train, sr_train = load_audio_files(train_path)\n",
    "signals_eval, sr_eval = load_audio_files(eval_path)\n",
    "\n",
    "def get_ids(path, signals):\n",
    "  ids = extract_labels(path)\n",
    "\n",
    "  ids_signals = {}\n",
    "  for i, signal in zip(ids, signals):\n",
    "    ids_signals[i] = signal\n",
    "  \n",
    "  return ids_signals, ids\n",
    "\n",
    "id_signal_dict_train, ids_train = get_ids(train_path, signals_train)\n",
    "# id_signal_dict_train\n",
    "id_signal_dict_eval, ids_eval = get_ids(eval_path, signals_eval )\n",
    "ids_train = pd.to_numeric(ids_train)\n",
    "ids_eval = pd.to_numeric(ids_eval)\n",
    "ids_train_combaciati = [x - 1 for x in ids_train]\n",
    "ids_eval_combaciati = [x - 1 for x in ids_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Funzione per creare e applicare il filtro passa basso\n",
    "def filter_signal(s, cutoff, sr, order=4):\n",
    "  nyquist = 0.5 * sr\n",
    "  normal_cutoff = cutoff / nyquist\n",
    "  b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "  filtered_signal = filtfilt(b, a, s)\n",
    "\n",
    "  return filtered_signal\n",
    "\n",
    "filtered_signals_train = [filter_signal(s, cutoff=4000, sr=sr_train) for s in signals_train]\n",
    "filtered_signals_eval = [filter_signal(s, cutoff=4000, sr=sr_eval) for s in signals_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_len_train = [len(s) / sr_train for s in filtered_signals_train]\n",
    "time_len_eval = [len(s) / sr_train for s in filtered_signals_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_len_train = pd.DataFrame(time_len_train)\n",
    "df_time_len_train['Id'] = ids_train_combaciati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_len_eval = pd.DataFrame(time_len_eval)\n",
    "df_time_len_eval['Id'] = ids_eval_combaciati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_signals(filtered_signals_train, filtered_signals_eval, sr_train, sr_eval, duration):\n",
    "\n",
    "  num_samples_train = int(duration * sr_train)\n",
    "  num_samples_eval = int(duration * sr_eval)\n",
    "\n",
    "  cutted_filtered_signals_train = [s[:num_samples_train] for s in filtered_signals_train]\n",
    "  cutted_filtered_signals_eval = [s[:num_samples_eval] for s in filtered_signals_eval]\n",
    "  return cutted_filtered_signals_train, cutted_filtered_signals_eval\n",
    "\n",
    "\n",
    "cutted_filtered_signals_train5s, cutted_filtered_signals_eval5s = cut_signals(filtered_signals_train, filtered_signals_eval, sr_train, sr_eval,  duration=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "import librosa\n",
    "\n",
    "def extract_and_merge_features(filtered_signals_train, filtered_signals_eval, sr_train, sr_eval, ids_train_combaciati, ids_eval_combaciati, df_time_len_train, df_time_len_eval):\n",
    "  def extract_time_features(s, sr):\n",
    "    rms_energy = librosa.feature.rms(y=s)\n",
    "    rms_energy_mean = np.mean(rms_energy)\n",
    "    rms_energy_median = np.median(rms_energy)\n",
    "    rms_energy_sd = np.std(rms_energy)\n",
    "    time_mean = np.mean(np.abs(s))\n",
    "    time_sd = np.std(np.abs(s))\n",
    "    time_min = np.min(np.abs(s))\n",
    "    time_max = np.max(np.abs(s))\n",
    "    time_kurtosis = kurtosis(s)\n",
    "    time_skew = skew(s)\n",
    "\n",
    "    return {\n",
    "      'rms_energy_mean': rms_energy_mean,\n",
    "      'rms_energy_median': rms_energy_median,\n",
    "      'rms_energy_sd': rms_energy_sd,\n",
    "      'time_mean': time_mean,\n",
    "      'time_sd': time_sd,\n",
    "      'time_min': time_min,\n",
    "      'time_max': time_max,\n",
    "      'time_kurtosis': time_kurtosis,\n",
    "      'time_skew': time_skew,\n",
    "    }\n",
    "\n",
    "  def extract_frequency_features(y, sr):\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=16384, hop_length=512)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=16384, hop_length=512)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=16384, hop_length=512)\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y, n_fft=16384, hop_length=512)\n",
    "\n",
    "    return {\n",
    "      'spectral_rolloff_mean': np.mean(spectral_rolloff),\n",
    "      'spectral_rolloff_median': np.median(spectral_rolloff),\n",
    "      'spectral_rolloff_std': np.std(spectral_rolloff),\n",
    "      'spectral_bandwidth_mean': np.mean(spectral_bandwidth),\n",
    "      'spectral_bandwidth_median': np.median(spectral_bandwidth),\n",
    "      'spectral_bandwidth_std': np.std(spectral_bandwidth),\n",
    "      'spectral_centroid_mean': np.mean(spectral_centroid),\n",
    "      'spectral_centroid_median': np.median(spectral_centroid),\n",
    "      'spectral_centroid_std': np.std(spectral_centroid),\n",
    "      'spectral_flatness_mean': np.mean(spectral_flatness),\n",
    "      'spectral_flatness_median': np.median(spectral_flatness),\n",
    "      'spectral_flatness_std': np.std(spectral_flatness),\n",
    "    }\n",
    "\n",
    "  def extract_mfcc(signal, sr, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc, n_fft=16384, hop_length=512)\n",
    "    mfcc_mean = np.mean(mfccs, axis=1)\n",
    "    mfcc_median = np.median(mfccs, axis=1)\n",
    "    mfcc_std = np.std(mfccs, axis=1)\n",
    "\n",
    "    features = {}\n",
    "    for i in range(n_mfcc):\n",
    "      features[f'MFCC{i+1}_mean'] = mfcc_mean[i]\n",
    "      features[f'MFCC{i+1}_median'] = mfcc_median[i]\n",
    "      features[f'MFCC{i+1}_std'] = mfcc_std[i]\n",
    "\n",
    "    return features\n",
    "\n",
    "  def extract_chroma(signal, sr, n_chroma=12, n_fft=16384, hop_length=512):\n",
    "    chroma = librosa.feature.chroma_stft(y=signal, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    chroma_median = np.median(chroma, axis=1)\n",
    "    chroma_std = np.std(chroma, axis=1)\n",
    "\n",
    "    features = {}\n",
    "    for i in range(n_chroma):\n",
    "      features[f'Chroma{i+1}_mean'] = chroma_mean[i]\n",
    "      features[f'Chroma{i+1}_median'] = chroma_median[i]\n",
    "      features[f'Chroma{i+1}_std'] = chroma_std[i]\n",
    "\n",
    "    return features\n",
    "\n",
    "  def extract_fundamental_frequencies(signal, sr, n_fft=8192, hop_length=256, fmin=25, fmax=500):\n",
    "    f0, _, _ = librosa.pyin(signal, fmin=fmin, fmax=fmax, sr=sr, frame_length=n_fft, hop_length=hop_length)\n",
    "    f0 = f0[~np.isnan(f0)]\n",
    "    f0_mean = np.mean(f0)\n",
    "    f0_median = np.median(f0)\n",
    "    f0_std = np.std(f0)\n",
    "\n",
    "    return {\n",
    "      'fundamental_frequency_mean': f0_mean,\n",
    "      'fundamental_frequency_median': f0_median,\n",
    "      'fundamental_frequency_std': f0_std,\n",
    "    }\n",
    "\n",
    "  def extract_amplitude_envelope(signal, n_fft=8192, hop_length=512):\n",
    "    frame_size = n_fft\n",
    "    amplitude_envelope = [np.max(signal[i:i+frame_size]) for i in range(0, len(signal), hop_length)]\n",
    "    amplitude_mean = np.mean(amplitude_envelope)\n",
    "    amplitude_median = np.median(amplitude_envelope)\n",
    "    amplitude_std = np.std(amplitude_envelope)\n",
    "\n",
    "    return {\n",
    "      'amplitude_envelope_mean': amplitude_mean,\n",
    "      'amplitude_envelope_median': amplitude_median,\n",
    "      'amplitude_envelope_std': amplitude_std,\n",
    "    }\n",
    "\n",
    "  time_features_train = [extract_time_features(s, sr_train) for s in filtered_signals_train]\n",
    "  time_features_eval = [extract_time_features(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  frequency_features_train = [extract_frequency_features(s, sr_train) for s in filtered_signals_train]\n",
    "  frequency_features_eval = [extract_frequency_features(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  mfcc_features_train = [extract_mfcc(s, sr_train) for s in filtered_signals_train]\n",
    "  mfcc_features_eval = [extract_mfcc(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  chroma_features_train = [extract_chroma(s, sr_train) for s in filtered_signals_train]\n",
    "  chroma_features_eval = [extract_chroma(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  fundamental_frequency_train = [extract_fundamental_frequencies(s, sr_train) for s in filtered_signals_train]\n",
    "  fundamental_frequency_eval = [extract_fundamental_frequencies(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  amplitude_envelope_train = [extract_amplitude_envelope(s, sr_train) for s in filtered_signals_train]\n",
    "  amplitude_envelope_eval = [extract_amplitude_envelope(s, sr_eval) for s in filtered_signals_eval]\n",
    "\n",
    "  df_time_features_train = pd.DataFrame(time_features_train)\n",
    "  df_time_features_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_time_features_eval = pd.DataFrame(time_features_eval)\n",
    "  df_time_features_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "  df_frequency_features_train = pd.DataFrame(frequency_features_train)\n",
    "  df_frequency_features_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_frequency_features_eval = pd.DataFrame(frequency_features_eval)\n",
    "  df_frequency_features_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "  df_mfccs_train = pd.DataFrame(mfcc_features_train)\n",
    "  df_mfccs_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_mfccs_eval = pd.DataFrame(mfcc_features_eval)\n",
    "  df_mfccs_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "  df_chroma_train = pd.DataFrame(chroma_features_train)\n",
    "  df_chroma_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_chroma_eval = pd.DataFrame(chroma_features_eval)\n",
    "  df_chroma_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "  df_fundamental_frequency_train = pd.DataFrame(fundamental_frequency_train)\n",
    "  df_fundamental_frequency_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_fundamental_frequency_eval = pd.DataFrame(fundamental_frequency_eval)\n",
    "  df_fundamental_frequency_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "  df_amplitude_envelope_train = pd.DataFrame(amplitude_envelope_train)\n",
    "  df_amplitude_envelope_train['Id'] = ids_train_combaciati\n",
    "\n",
    "  df_amplitude_envelope_eval = pd.DataFrame(amplitude_envelope_eval)\n",
    "  df_amplitude_envelope_eval['Id'] = ids_eval_combaciati\n",
    "\n",
    "\n",
    "  df_train = pd.merge(df_time_features_train, df_frequency_features_train, on='Id', how='inner')\n",
    "  df_train = pd.merge(df_train, df_mfccs_train, on='Id', how='inner')\n",
    "  df_train = pd.merge(df_train, df_chroma_train, on='Id', how='inner')\n",
    "  df_train = pd.merge(df_train, df_fundamental_frequency_train, on='Id', how='inner')\n",
    "  df_train = pd.merge(df_train, df_amplitude_envelope_train, on='Id', how='inner')\n",
    "  df_train = pd.merge(df_train, df_time_len_train, on='Id', how='inner')\n",
    "\n",
    "  df_eval = pd.merge(df_time_features_eval, df_frequency_features_eval, on='Id', how='inner')\n",
    "  df_eval = pd.merge(df_eval, df_mfccs_eval, on='Id', how='inner')\n",
    "  df_eval = pd.merge(df_eval, df_chroma_eval, on='Id', how='inner')\n",
    "  df_eval = pd.merge(df_eval, df_fundamental_frequency_eval, on='Id', how='inner')\n",
    "  df_eval = pd.merge(df_eval, df_amplitude_envelope_eval, on='Id', how='inner')\n",
    "  df_eval = pd.merge(df_eval, df_time_len_eval, on='Id', how='inner')\n",
    "\n",
    "  df_combined = pd.concat([df_train, df_eval], axis=0)\n",
    "\n",
    "  return df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=16384 is too large for input signal of length=14737\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "df_features = extract_and_merge_features(cutted_filtered_signals_train5s, cutted_filtered_signals_eval5s, sr_train, sr_eval, ids_train_combaciati, ids_eval_combaciati, df_time_len_train, df_time_len_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('/Users/fabiodepetro/DSL_Project/ProvaProgetto/DSL_Winter_Project_2025/development.csv')\n",
    "df_eval = pd.read_csv('/Users/fabiodepetro/DSL_Project/ProvaProgetto/DSL_Winter_Project_2025/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2933, 691, 3624)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_dev, df_eval], sort=False)\n",
    "len(df_dev), len(df_eval), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_features = df_features.iloc[:2933]\n",
    "df_eval_features = df_features.tail(df_features.shape[0]-2933)\n",
    "df_dev_total = pd.merge(df_dev, df_dev_features, on='Id', how='inner')\n",
    "df_eval_total = pd.merge(df_eval, df_eval_features, on='Id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>max_pitch</th>\n",
       "      <th>min_pitch</th>\n",
       "      <th>jitter</th>\n",
       "      <th>shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Chroma12_mean</th>\n",
       "      <th>Chroma12_median</th>\n",
       "      <th>Chroma12_std</th>\n",
       "      <th>fundamental_frequency_mean</th>\n",
       "      <th>fundamental_frequency_median</th>\n",
       "      <th>fundamental_frequency_std</th>\n",
       "      <th>amplitude_envelope_mean</th>\n",
       "      <th>amplitude_envelope_median</th>\n",
       "      <th>amplitude_envelope_std</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22050</td>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>arabic</td>\n",
       "      <td>1821.69060</td>\n",
       "      <td>3999.7170</td>\n",
       "      <td>145.43066</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284390</td>\n",
       "      <td>0.159516</td>\n",
       "      <td>0.309165</td>\n",
       "      <td>280.201810</td>\n",
       "      <td>284.481204</td>\n",
       "      <td>76.990362</td>\n",
       "      <td>0.279256</td>\n",
       "      <td>0.234448</td>\n",
       "      <td>0.157617</td>\n",
       "      <td>35.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22050</td>\n",
       "      <td>22.5</td>\n",
       "      <td>female</td>\n",
       "      <td>hungarian</td>\n",
       "      <td>1297.81870</td>\n",
       "      <td>3998.8590</td>\n",
       "      <td>145.37268</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235085</td>\n",
       "      <td>0.126637</td>\n",
       "      <td>0.276171</td>\n",
       "      <td>209.628549</td>\n",
       "      <td>204.674778</td>\n",
       "      <td>22.039430</td>\n",
       "      <td>0.384136</td>\n",
       "      <td>0.281566</td>\n",
       "      <td>0.122184</td>\n",
       "      <td>23.331293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>1332.85240</td>\n",
       "      <td>3998.8025</td>\n",
       "      <td>145.42395</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.275919</td>\n",
       "      <td>0.349890</td>\n",
       "      <td>178.202631</td>\n",
       "      <td>214.354693</td>\n",
       "      <td>83.780137</td>\n",
       "      <td>0.364011</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>21.667891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>1430.34990</td>\n",
       "      <td>3998.4510</td>\n",
       "      <td>147.98083</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.102389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155145</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.146220</td>\n",
       "      <td>228.292126</td>\n",
       "      <td>224.492410</td>\n",
       "      <td>49.859493</td>\n",
       "      <td>0.649081</td>\n",
       "      <td>0.684984</td>\n",
       "      <td>0.083701</td>\n",
       "      <td>22.476961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1688.72340</td>\n",
       "      <td>3998.6113</td>\n",
       "      <td>145.44772</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>0.124831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364694</td>\n",
       "      <td>0.258917</td>\n",
       "      <td>0.320842</td>\n",
       "      <td>121.120608</td>\n",
       "      <td>109.050773</td>\n",
       "      <td>29.340614</td>\n",
       "      <td>0.390123</td>\n",
       "      <td>0.346465</td>\n",
       "      <td>0.108384</td>\n",
       "      <td>19.090295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>22050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>igbo</td>\n",
       "      <td>570.62740</td>\n",
       "      <td>3900.6730</td>\n",
       "      <td>145.67577</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575447</td>\n",
       "      <td>0.671069</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>108.426812</td>\n",
       "      <td>119.609612</td>\n",
       "      <td>40.071467</td>\n",
       "      <td>0.366293</td>\n",
       "      <td>0.383727</td>\n",
       "      <td>0.147121</td>\n",
       "      <td>2.024490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>22050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>igbo</td>\n",
       "      <td>974.13965</td>\n",
       "      <td>3919.0024</td>\n",
       "      <td>145.90408</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>0.117492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>0.178327</td>\n",
       "      <td>0.272512</td>\n",
       "      <td>61.593122</td>\n",
       "      <td>51.465112</td>\n",
       "      <td>28.159212</td>\n",
       "      <td>0.171333</td>\n",
       "      <td>0.089318</td>\n",
       "      <td>0.178207</td>\n",
       "      <td>4.947211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>22050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>serbian</td>\n",
       "      <td>1113.27650</td>\n",
       "      <td>3999.3510</td>\n",
       "      <td>145.38307</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206062</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>0.295049</td>\n",
       "      <td>194.536542</td>\n",
       "      <td>183.400809</td>\n",
       "      <td>49.264104</td>\n",
       "      <td>0.532887</td>\n",
       "      <td>0.610292</td>\n",
       "      <td>0.115757</td>\n",
       "      <td>27.485306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689</td>\n",
       "      <td>22050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>spanish</td>\n",
       "      <td>1759.17420</td>\n",
       "      <td>3999.4610</td>\n",
       "      <td>145.56773</td>\n",
       "      <td>0.026118</td>\n",
       "      <td>0.106429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400657</td>\n",
       "      <td>0.308231</td>\n",
       "      <td>0.270338</td>\n",
       "      <td>143.914523</td>\n",
       "      <td>141.421356</td>\n",
       "      <td>50.750295</td>\n",
       "      <td>0.424355</td>\n",
       "      <td>0.381707</td>\n",
       "      <td>0.172068</td>\n",
       "      <td>21.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>690</td>\n",
       "      <td>22050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>igbo</td>\n",
       "      <td>779.53890</td>\n",
       "      <td>3972.4630</td>\n",
       "      <td>147.44424</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.108114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.236083</td>\n",
       "      <td>0.387411</td>\n",
       "      <td>153.153991</td>\n",
       "      <td>151.571657</td>\n",
       "      <td>6.212033</td>\n",
       "      <td>0.230030</td>\n",
       "      <td>0.243728</td>\n",
       "      <td>0.130448</td>\n",
       "      <td>1.262358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3624 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  sampling_rate   age  gender   ethnicity  mean_pitch  max_pitch  \\\n",
       "0      0          22050  24.0  female      arabic  1821.69060  3999.7170   \n",
       "1      1          22050  22.5  female   hungarian  1297.81870  3998.8590   \n",
       "2      2          22050  22.0  female  portuguese  1332.85240  3998.8025   \n",
       "3      3          22050  22.0  female     english  1430.34990  3998.4510   \n",
       "4      4          22050  22.0    male       dutch  1688.72340  3998.6113   \n",
       "..   ...            ...   ...     ...         ...         ...        ...   \n",
       "686  686          22050   NaN    male        igbo   570.62740  3900.6730   \n",
       "687  687          22050   NaN    male        igbo   974.13965  3919.0024   \n",
       "688  688          22050   NaN  female     serbian  1113.27650  3999.3510   \n",
       "689  689          22050   NaN    male     spanish  1759.17420  3999.4610   \n",
       "690  690          22050   NaN    male        igbo   779.53890  3972.4630   \n",
       "\n",
       "     min_pitch    jitter   shimmer  ...  Chroma12_mean  Chroma12_median  \\\n",
       "0    145.43066  0.013795  0.082725  ...       0.284390         0.159516   \n",
       "1    145.37268  0.025349  0.096242  ...       0.235085         0.126637   \n",
       "2    145.42395  0.019067  0.119456  ...       0.420667         0.275919   \n",
       "3    147.98083  0.017004  0.102389  ...       0.155145         0.111702   \n",
       "4    145.44772  0.028027  0.124831  ...       0.364694         0.258917   \n",
       "..         ...       ...       ...  ...            ...              ...   \n",
       "686  145.67577  0.018842  0.079197  ...       0.575447         0.671069   \n",
       "687  145.90408  0.024367  0.117492  ...       0.248571         0.178327   \n",
       "688  145.38307  0.020637  0.089355  ...       0.206062         0.049989   \n",
       "689  145.56773  0.026118  0.106429  ...       0.400657         0.308231   \n",
       "690  147.44424  0.010952  0.108114  ...       0.459528         0.236083   \n",
       "\n",
       "     Chroma12_std fundamental_frequency_mean  fundamental_frequency_median  \\\n",
       "0        0.309165                 280.201810                    284.481204   \n",
       "1        0.276171                 209.628549                    204.674778   \n",
       "2        0.349890                 178.202631                    214.354693   \n",
       "3        0.146220                 228.292126                    224.492410   \n",
       "4        0.320842                 121.120608                    109.050773   \n",
       "..            ...                        ...                           ...   \n",
       "686      0.395700                 108.426812                    119.609612   \n",
       "687      0.272512                  61.593122                     51.465112   \n",
       "688      0.295049                 194.536542                    183.400809   \n",
       "689      0.270338                 143.914523                    141.421356   \n",
       "690      0.387411                 153.153991                    151.571657   \n",
       "\n",
       "     fundamental_frequency_std  amplitude_envelope_mean  \\\n",
       "0                    76.990362                 0.279256   \n",
       "1                    22.039430                 0.384136   \n",
       "2                    83.780137                 0.364011   \n",
       "3                    49.859493                 0.649081   \n",
       "4                    29.340614                 0.390123   \n",
       "..                         ...                      ...   \n",
       "686                  40.071467                 0.366293   \n",
       "687                  28.159212                 0.171333   \n",
       "688                  49.264104                 0.532887   \n",
       "689                  50.750295                 0.424355   \n",
       "690                   6.212033                 0.230030   \n",
       "\n",
       "     amplitude_envelope_median  amplitude_envelope_std          0  \n",
       "0                     0.234448                0.157617  35.095238  \n",
       "1                     0.281566                0.122184  23.331293  \n",
       "2                     0.296423                0.093786  21.667891  \n",
       "3                     0.684984                0.083701  22.476961  \n",
       "4                     0.346465                0.108384  19.090295  \n",
       "..                         ...                     ...        ...  \n",
       "686                   0.383727                0.147121   2.024490  \n",
       "687                   0.089318                0.178207   4.947211  \n",
       "688                   0.610292                0.115757  27.485306  \n",
       "689                   0.381707                0.172068  21.632653  \n",
       "690                   0.243728                0.130448   1.262358  \n",
       "\n",
       "[3624 rows x 123 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.concat([df_dev_total, df_eval_total], axis = 0)\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.columns.values[122] = 'time_len'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('../datasets/df_features_extracted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
